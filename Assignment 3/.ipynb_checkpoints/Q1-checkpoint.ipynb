{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67eaff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "\n",
    "%matplotlib inline \n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d04f8fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.433735</td>\n",
       "      <td>1.922353</td>\n",
       "      <td>1.397627</td>\n",
       "      <td>-1.191657</td>\n",
       "      <td>0.444606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.842763</td>\n",
       "      <td>5.869047</td>\n",
       "      <td>4.310030</td>\n",
       "      <td>2.101013</td>\n",
       "      <td>0.497103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.042100</td>\n",
       "      <td>-13.773100</td>\n",
       "      <td>-5.286100</td>\n",
       "      <td>-8.548200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.773000</td>\n",
       "      <td>-1.708200</td>\n",
       "      <td>-1.574975</td>\n",
       "      <td>-2.413450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.496180</td>\n",
       "      <td>2.319650</td>\n",
       "      <td>0.616630</td>\n",
       "      <td>-0.586650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.821475</td>\n",
       "      <td>6.814625</td>\n",
       "      <td>3.179250</td>\n",
       "      <td>0.394810</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.824800</td>\n",
       "      <td>12.951600</td>\n",
       "      <td>17.927400</td>\n",
       "      <td>2.449500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          variance     skewness     curtosis      entropy        class\n",
       "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000\n",
       "mean      0.433735     1.922353     1.397627    -1.191657     0.444606\n",
       "std       2.842763     5.869047     4.310030     2.101013     0.497103\n",
       "min      -7.042100   -13.773100    -5.286100    -8.548200     0.000000\n",
       "25%      -1.773000    -1.708200    -1.574975    -2.413450     0.000000\n",
       "50%       0.496180     2.319650     0.616630    -0.586650     0.000000\n",
       "75%       2.821475     6.814625     3.179250     0.394810     1.000000\n",
       "max       6.824800    12.951600    17.927400     2.449500     1.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames = ['variance','skewness','curtosis','entropy','class'] ##List of column names of dataset\n",
    "dataset = pd.read_csv('banknote.txt',names = colnames) ##Reads the dataset into Datafra,e\n",
    "dataset.head(100)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b7f78a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.433735</td>\n",
       "      <td>1.922353</td>\n",
       "      <td>1.397627</td>\n",
       "      <td>-1.191657</td>\n",
       "      <td>-0.110787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.842763</td>\n",
       "      <td>5.869047</td>\n",
       "      <td>4.310030</td>\n",
       "      <td>2.101013</td>\n",
       "      <td>0.994207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.042100</td>\n",
       "      <td>-13.773100</td>\n",
       "      <td>-5.286100</td>\n",
       "      <td>-8.548200</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.773000</td>\n",
       "      <td>-1.708200</td>\n",
       "      <td>-1.574975</td>\n",
       "      <td>-2.413450</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.496180</td>\n",
       "      <td>2.319650</td>\n",
       "      <td>0.616630</td>\n",
       "      <td>-0.586650</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.821475</td>\n",
       "      <td>6.814625</td>\n",
       "      <td>3.179250</td>\n",
       "      <td>0.394810</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.824800</td>\n",
       "      <td>12.951600</td>\n",
       "      <td>17.927400</td>\n",
       "      <td>2.449500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          variance     skewness     curtosis      entropy        class\n",
       "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000\n",
       "mean      0.433735     1.922353     1.397627    -1.191657    -0.110787\n",
       "std       2.842763     5.869047     4.310030     2.101013     0.994207\n",
       "min      -7.042100   -13.773100    -5.286100    -8.548200    -1.000000\n",
       "25%      -1.773000    -1.708200    -1.574975    -2.413450    -1.000000\n",
       "50%       0.496180     2.319650     0.616630    -0.586650    -1.000000\n",
       "75%       2.821475     6.814625     3.179250     0.394810     1.000000\n",
       "max       6.824800    12.951600    17.927400     2.449500     1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['class'].replace(0,-1,inplace =True)##Converts Class labels from 0 to -1 as required for algorithm\n",
    "dataset.head(25)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37d39e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Shape : (1372, 5)\n",
      "Dataset Shape after removing duplicates : (1348, 5)\n"
     ]
    }
   ],
   "source": [
    "duplicate = dataset[dataset.duplicated()] ##Checks if Duplicate Rows present\n",
    "print('Original Dataset Shape :',dataset.shape)\n",
    "if(len(duplicate)!=0):\n",
    "    dataset.drop_duplicates(inplace = True) ## If duplicate rows are found then they are dropped\n",
    "    print('Dataset Shape after removing duplicates :',dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cbea311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Shape : (348, 5)\n"
     ]
    }
   ],
   "source": [
    "##Creates a held out Validation Set\n",
    "validation = dataset.sample(frac=0.2582)\n",
    "print('Validation Set Shape :',validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb50a6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape : (1000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.621600</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.80730</td>\n",
       "      <td>-0.446990</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.545900</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.45860</td>\n",
       "      <td>-1.462100</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.866000</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.92420</td>\n",
       "      <td>0.106450</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.456600</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.01120</td>\n",
       "      <td>-3.594400</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.329240</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.57180</td>\n",
       "      <td>-0.988800</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.368400</td>\n",
       "      <td>9.67180</td>\n",
       "      <td>-3.96060</td>\n",
       "      <td>-3.162500</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.591200</td>\n",
       "      <td>3.01290</td>\n",
       "      <td>0.72888</td>\n",
       "      <td>0.564210</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.092200</td>\n",
       "      <td>-6.81000</td>\n",
       "      <td>8.46360</td>\n",
       "      <td>-0.602160</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.203200</td>\n",
       "      <td>5.75880</td>\n",
       "      <td>-0.75345</td>\n",
       "      <td>-0.612510</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.535600</td>\n",
       "      <td>9.17720</td>\n",
       "      <td>-2.27180</td>\n",
       "      <td>-0.735350</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.224700</td>\n",
       "      <td>8.77790</td>\n",
       "      <td>-2.21350</td>\n",
       "      <td>-0.806470</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.989900</td>\n",
       "      <td>-2.70660</td>\n",
       "      <td>2.39460</td>\n",
       "      <td>0.862910</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.899300</td>\n",
       "      <td>7.66250</td>\n",
       "      <td>0.15394</td>\n",
       "      <td>-3.110800</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.576800</td>\n",
       "      <td>10.84300</td>\n",
       "      <td>2.54620</td>\n",
       "      <td>-2.936200</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.404000</td>\n",
       "      <td>8.72610</td>\n",
       "      <td>-2.99150</td>\n",
       "      <td>-0.572420</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.676500</td>\n",
       "      <td>-3.38950</td>\n",
       "      <td>3.48960</td>\n",
       "      <td>1.477100</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.671900</td>\n",
       "      <td>3.06460</td>\n",
       "      <td>0.37158</td>\n",
       "      <td>0.586190</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.803550</td>\n",
       "      <td>2.84730</td>\n",
       "      <td>4.34390</td>\n",
       "      <td>0.601700</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.447900</td>\n",
       "      <td>-4.87940</td>\n",
       "      <td>8.34280</td>\n",
       "      <td>-2.108600</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.242300</td>\n",
       "      <td>11.02720</td>\n",
       "      <td>-4.35300</td>\n",
       "      <td>-4.101300</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.786700</td>\n",
       "      <td>7.89020</td>\n",
       "      <td>-2.61960</td>\n",
       "      <td>-0.487080</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.329200</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.57180</td>\n",
       "      <td>-0.988800</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.936200</td>\n",
       "      <td>10.16220</td>\n",
       "      <td>-3.82350</td>\n",
       "      <td>-4.017200</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.935840</td>\n",
       "      <td>8.88550</td>\n",
       "      <td>-1.68310</td>\n",
       "      <td>-1.659900</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.433800</td>\n",
       "      <td>9.88700</td>\n",
       "      <td>-4.67950</td>\n",
       "      <td>-3.748300</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.705700</td>\n",
       "      <td>-5.49810</td>\n",
       "      <td>8.33680</td>\n",
       "      <td>-2.871500</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.143200</td>\n",
       "      <td>-3.74130</td>\n",
       "      <td>5.57770</td>\n",
       "      <td>-0.635780</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.382140</td>\n",
       "      <td>8.39090</td>\n",
       "      <td>2.16240</td>\n",
       "      <td>-3.740500</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.563300</td>\n",
       "      <td>9.81870</td>\n",
       "      <td>-4.41130</td>\n",
       "      <td>-3.225800</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.890600</td>\n",
       "      <td>-3.35840</td>\n",
       "      <td>3.42020</td>\n",
       "      <td>1.090500</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.248110</td>\n",
       "      <td>-0.17797</td>\n",
       "      <td>4.90680</td>\n",
       "      <td>0.154290</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.488400</td>\n",
       "      <td>3.62740</td>\n",
       "      <td>3.30800</td>\n",
       "      <td>0.489210</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4.296900</td>\n",
       "      <td>7.61700</td>\n",
       "      <td>-2.38740</td>\n",
       "      <td>-0.961640</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.965110</td>\n",
       "      <td>9.41110</td>\n",
       "      <td>1.73050</td>\n",
       "      <td>-4.862900</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-1.616200</td>\n",
       "      <td>0.80908</td>\n",
       "      <td>8.16280</td>\n",
       "      <td>0.608170</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2.439100</td>\n",
       "      <td>6.44170</td>\n",
       "      <td>-0.80743</td>\n",
       "      <td>-0.691390</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2.688100</td>\n",
       "      <td>6.01950</td>\n",
       "      <td>-0.46641</td>\n",
       "      <td>-0.692680</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3.628900</td>\n",
       "      <td>0.81322</td>\n",
       "      <td>1.62770</td>\n",
       "      <td>0.776270</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4.567900</td>\n",
       "      <td>3.19290</td>\n",
       "      <td>-2.10550</td>\n",
       "      <td>0.296530</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3.480500</td>\n",
       "      <td>9.70080</td>\n",
       "      <td>-3.75410</td>\n",
       "      <td>-3.437900</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4.171100</td>\n",
       "      <td>8.72200</td>\n",
       "      <td>-3.02240</td>\n",
       "      <td>-0.596990</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.206200</td>\n",
       "      <td>9.22070</td>\n",
       "      <td>-3.70440</td>\n",
       "      <td>-6.810300</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-0.006892</td>\n",
       "      <td>9.29310</td>\n",
       "      <td>-0.41243</td>\n",
       "      <td>-1.963800</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.964410</td>\n",
       "      <td>5.83950</td>\n",
       "      <td>2.32350</td>\n",
       "      <td>0.066365</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2.856100</td>\n",
       "      <td>6.91760</td>\n",
       "      <td>-0.79372</td>\n",
       "      <td>0.484030</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.786900</td>\n",
       "      <td>9.56630</td>\n",
       "      <td>-3.78670</td>\n",
       "      <td>-7.503400</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2.084300</td>\n",
       "      <td>6.62580</td>\n",
       "      <td>0.48382</td>\n",
       "      <td>-2.213400</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3.910200</td>\n",
       "      <td>6.06500</td>\n",
       "      <td>-2.45340</td>\n",
       "      <td>-0.682340</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.634900</td>\n",
       "      <td>3.28600</td>\n",
       "      <td>2.87530</td>\n",
       "      <td>0.087054</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4.323900</td>\n",
       "      <td>-4.88350</td>\n",
       "      <td>3.43560</td>\n",
       "      <td>-0.577600</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    variance  skewness  curtosis   entropy  class\n",
       "0   3.621600   8.66610  -2.80730 -0.446990     -1\n",
       "1   4.545900   8.16740  -2.45860 -1.462100     -1\n",
       "2   3.866000  -2.63830   1.92420  0.106450     -1\n",
       "3   3.456600   9.52280  -4.01120 -3.594400     -1\n",
       "4   0.329240  -4.45520   4.57180 -0.988800     -1\n",
       "5   4.368400   9.67180  -3.96060 -3.162500     -1\n",
       "6   3.591200   3.01290   0.72888  0.564210     -1\n",
       "7   2.092200  -6.81000   8.46360 -0.602160     -1\n",
       "8   3.203200   5.75880  -0.75345 -0.612510     -1\n",
       "9   1.535600   9.17720  -2.27180 -0.735350     -1\n",
       "10  1.224700   8.77790  -2.21350 -0.806470     -1\n",
       "11  3.989900  -2.70660   2.39460  0.862910     -1\n",
       "12  1.899300   7.66250   0.15394 -3.110800     -1\n",
       "13 -1.576800  10.84300   2.54620 -2.936200     -1\n",
       "14  3.404000   8.72610  -2.99150 -0.572420     -1\n",
       "15  4.676500  -3.38950   3.48960  1.477100     -1\n",
       "16  2.671900   3.06460   0.37158  0.586190     -1\n",
       "17  0.803550   2.84730   4.34390  0.601700     -1\n",
       "18  1.447900  -4.87940   8.34280 -2.108600     -1\n",
       "19  5.242300  11.02720  -4.35300 -4.101300     -1\n",
       "20  5.786700   7.89020  -2.61960 -0.487080     -1\n",
       "21  0.329200  -4.45520   4.57180 -0.988800     -1\n",
       "22  3.936200  10.16220  -3.82350 -4.017200     -1\n",
       "23  0.935840   8.88550  -1.68310 -1.659900     -1\n",
       "24  4.433800   9.88700  -4.67950 -3.748300     -1\n",
       "25  0.705700  -5.49810   8.33680 -2.871500     -1\n",
       "26  1.143200  -3.74130   5.57770 -0.635780     -1\n",
       "27 -0.382140   8.39090   2.16240 -3.740500     -1\n",
       "28  6.563300   9.81870  -4.41130 -3.225800     -1\n",
       "29  4.890600  -3.35840   3.42020  1.090500     -1\n",
       "30 -0.248110  -0.17797   4.90680  0.154290     -1\n",
       "31  1.488400   3.62740   3.30800  0.489210     -1\n",
       "32  4.296900   7.61700  -2.38740 -0.961640     -1\n",
       "33 -0.965110   9.41110   1.73050 -4.862900     -1\n",
       "34 -1.616200   0.80908   8.16280  0.608170     -1\n",
       "35  2.439100   6.44170  -0.80743 -0.691390     -1\n",
       "36  2.688100   6.01950  -0.46641 -0.692680     -1\n",
       "37  3.628900   0.81322   1.62770  0.776270     -1\n",
       "38  4.567900   3.19290  -2.10550  0.296530     -1\n",
       "39  3.480500   9.70080  -3.75410 -3.437900     -1\n",
       "40  4.171100   8.72200  -3.02240 -0.596990     -1\n",
       "41 -0.206200   9.22070  -3.70440 -6.810300     -1\n",
       "42 -0.006892   9.29310  -0.41243 -1.963800     -1\n",
       "43  0.964410   5.83950   2.32350  0.066365     -1\n",
       "44  2.856100   6.91760  -0.79372  0.484030     -1\n",
       "45 -0.786900   9.56630  -3.78670 -7.503400     -1\n",
       "46  2.084300   6.62580   0.48382 -2.213400     -1\n",
       "48  3.910200   6.06500  -2.45340 -0.682340     -1\n",
       "49  1.634900   3.28600   2.87530  0.087054     -1\n",
       "50  4.323900  -4.88350   3.43560 -0.577600     -1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Forms Training Set by removing rows which are present in Validation Set\n",
    "\n",
    "##We perform outer join on dataset and Validation Set and keep only those rows which only came from dataset\n",
    "train = dataset.merge(validation, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='left_only']\n",
    "\n",
    "train.drop('_merge',axis='columns',inplace = True) ## We drop the extra column '_merge' added during merge operation\n",
    "print('Training Set Shape :',train.shape)\n",
    "dataset.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ff58d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Perceptron Algorithm as per Lecture Slides\n",
    "\n",
    "def percepalgo(X,Y,learn_rate,threshold):\n",
    "    w = np.array([1,1,1,1]) ##Initialize Weight Vector\n",
    "    nt = learn_rate ##Set Learning Rate\n",
    "    count = 0 ##Used to keep Track for how many iterations our model has not made any prediction mistake\n",
    "    k = threshold\n",
    "    while(True):\n",
    "        \n",
    "        randint = np.random.randint(0,len(Y)) ##Generates a random integer to be used select a random (xn,yn) pair\n",
    "        xn = np.array(X.iloc[randint])\n",
    "        yn = Y.iloc[randint]\n",
    "    \n",
    "        if(yn * np.sum(w*xn) < 0): ##Checks whether model has made a prediction mistake. if yes, then model weights are updated\n",
    "                                   ##and count is reset to 0. If No, then count is increased by 1\n",
    "        \n",
    "            w = w + nt*yn*xn\n",
    "            count = 0\n",
    "            \n",
    "        else:\n",
    "            count+=1\n",
    "        \n",
    "        if(count >k): ##Checks whether model has not made any mistakes in last k (threshold value passed) iterations, if yes then weights\n",
    "                        ##have converged and if we stop the loop. If No, then we continue checking predictions\n",
    "            break\n",
    "      \n",
    "       \n",
    "    return w ##Returns the converged weight vector\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9af83bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function to make Predictions\n",
    "\n",
    "def predictions(X,w): ##Takes parameters as input vector X and converged weight vector w\n",
    "    \n",
    "    y_pred = np.round(np.sum(X*w,axis = 1)) ##Performs row wise element wise product of weight vector and input vector and\n",
    "                                            ##takes it sum and rounds to nearest integer.\n",
    "    \n",
    "    y_pred[y_pred >= 0]  = 1 ##If predicted y value is gretaer than or equal to 0 we store class label as 1\n",
    "    y_pred[y_pred < 0]  = -1 ##If predicted y value is less than 0 we store class label as -1\n",
    "   \n",
    "    \n",
    "    return y_pred ##Returns array of predicted class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82ce6fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function To calculate Error made by model. We have taken error function has percentage of misclassifications by model.\n",
    "\n",
    "def error(yn,y_pred):\n",
    "   \n",
    "    count = 0\n",
    "    for i in range(len(yn)):\n",
    "        if(yn[i]!=y_pred[i]):\n",
    "            count+=1\n",
    "    return((count/len(yn))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34727f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model weights :  [-11.08176065  -7.6350983   -7.33905558  -5.28575598] with average error of 4.4 %\n",
      "Best Learning Rate with Minimum Average Error is 0.30000000000000004\n"
     ]
    }
   ],
   "source": [
    "## We perform 10-Fold Cross validation to determine value of Hyperparameter Learning Rate\n",
    "\n",
    "f = ['variance','skewness','curtosis','entropy'] \n",
    "\n",
    "error_min = 100 ## We initialize minimum error to 100%\n",
    "best_weight = np.array([]) ##Empty array to store Best Model weights\n",
    "best_learnrate = 0 ##Stores the learning rate for which Average weight is minimum\n",
    "\n",
    "for j in range(0,10): ##Loops over different values of Learing rate from 0.1 to 1 in steps of 0.1\n",
    "   \n",
    "    e = 0 ##Initialize error for particular current learning rate to 0\n",
    "    \n",
    "    w1 = np.array([0.0,0.0,0.0,0.0]) ##Array to store sum of weights for each fold in cross validation\n",
    "    \n",
    "    for i in range(0,10): ##loops over cross validation sets\n",
    "       \n",
    "        test = train[i*100:(i+1)*100] ##Splitted the training data into 9:1 ratio for train:test set\n",
    "        train_cross = pd.concat([train[0:i*100],train[(i+1)*100:]])\n",
    "        \n",
    "        w = percepalgo(train_cross[f],train_cross['class'],0.1*(j+1)) ##Finds Converged weight vector over a training set and learning rate\n",
    "        \n",
    "        y_pred = predictions(np.array(test[f]),w) ##Calculates the predicted class labels for the test set using converged weigth vector from above\n",
    "        \n",
    "        e += error(np.array(test['class']),np.array(y_pred)) ##Calculates model error and adds it to overall error for a learning rate\n",
    "        \n",
    "        w1 += w ##Adds the current weight vector to overall weight vector for a learning rate\n",
    "        \n",
    "    if(e/10 < error_min):  ##Checks if average error for this learning rate is lesser than current minimum error.\n",
    "                           ## IF yes, then we store minimum error as current average error for this learning rate , store the\n",
    "                           ## learning rate and also the average weight vector\n",
    "        error_min = e/10\n",
    "        best_weight = w1/10\n",
    "        best_learnrate = 0.1 *(j+1)\n",
    "   \n",
    "\n",
    "##Outputs the Best Model Parameters and corresponding learning rate\n",
    "print('Best Model weights : ',best_weight,'with average error of',error_min,'%')\n",
    "print('Best Learning Rate with Minimum Average Error is',best_learnrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e642b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function to calculate F- Score for a target class\n",
    "\n",
    "def fscorecalc(t,y_pred,yn):\n",
    "    tp = fp = fn = tn = 0 ##Initialixe True Positive (tp) , True Negative (tn) , False Positive (fp) and False Negative (fn) to 0\n",
    "    \n",
    "    for i in range(len(y_pred)): ##For each prediction checks if predicted value and given value is same, if same then\n",
    "                                 ##checks if predicted value is equal to target, if yes then True Positive else True Negative\n",
    "                                 ##If predicted value and actual value are not same, then check if predicted value same as target \n",
    "                                 ##then False Positive else False Negative\n",
    "        if(y_pred[i] == yn[i] ):\n",
    "            if(y_pred[i] == t):\n",
    "                tp+=1\n",
    "            else:\n",
    "                tn+=1\n",
    "        else:\n",
    "            if(y_pred[i]== t):\n",
    "                fp+=1\n",
    "            else:\n",
    "                fn+=1\n",
    "    \n",
    "    prec = tp / (tp + fp)    ##Precision is calculated as True Positive over sum of True Positive and False Positive\n",
    "    \n",
    "    recall = tp / (tp + fn)   ##Recall is claculated as True Positive over sum of True Positive and False Negative\n",
    "    \n",
    "    return (2*prec*recall) / (prec + recall) ##Returns F score which is calculated as harmonic mean of precision and recall\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "309e31c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of Best Model on Validation Set is  5.459770114942529 %\n",
      "F Score for class 1 is 0.9396825396825398\n",
      "F Score for class -1 is 0.9501312335958005\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictions(np.array(validation[f]),best_weight) ##Calculates predictions for Validation Set data\n",
    "\n",
    "print('Error of Best Model on Validation Set is ',error(np.array(validation['class']),np.array(y_pred)),'%') ##Model Error\n",
    "\n",
    "print('F Score for class 1 is',fscorecalc(1,y_pred,np.array(validation['class']))) ##F-Score for Class label '1'\n",
    "\n",
    "print('F Score for class -1 is',fscorecalc(-1,y_pred,np.array(validation['class']))) ##F-Score for class label '-1'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
